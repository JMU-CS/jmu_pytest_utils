#!/usr/bin/env bash

# This script is designed to run both on Gradescope and offline for testing.
# On Gradescope, the working directory is /autograder. When running offline,
# the working directory doesn't change, and grading files are created there.

if [ -d "/autograder/results" ]; then
    RES_DIR="/autograder/results"
else
    RES_DIR="."
fi
if [ -d "/autograder/source" ]; then
    cd /autograder/source
fi
if [ -d ".venv" ]; then
    source .venv/bin/activate
fi

# set autograder environment variables
source config.sh

# name of the current autograder step
NAME=$RES_DIR/NAME.txt
> $NAME

# file for capturing stdout and stderr
OUTPUT=$RES_DIR/OUTPUT.txt
> $OUTPUT

# output file required by Gradescope
RESULTS=$RES_DIR/results.json
> $RESULTS

# called if anything fails before pytest
function abort {
    echo -e "\nThis submission will not be counted toward the submission limit." >> $OUTPUT
    echo "{\"score\": 0, \"tests\": [{\"name\": $(jq -Rs . < $NAME), \"output\": $(jq -Rs . < $OUTPUT)}]}" > $RESULTS
    exit
}

# check for required files
if [ -d "/autograder/submission" ]; then
    cd /autograder/submission
fi
echo -n "Missing Files" > $NAME
for f in $SUBMISSION_FILES; do
    if [[ ! -f "$f" ]]; then
        echo "ERROR: $f not found" >> $OUTPUT
    fi
done
if [[ -s $OUTPUT ]]; then abort; fi

# if running on Gradescope
if [ -d "/autograder/submission" ]; then
    # reject any other files
    echo -n "Extra Files" > $NAME
    for f in $(find -type f -printf '%P\n'); do
        if [[ ! " $SUBMISSION_FILES " =~ .*\ $f\ .* ]]; then
            echo "ERROR: don't submit $f" >> $OUTPUT
        fi
    done
    if [[ -s $OUTPUT ]]; then abort; fi

    # copy files to source directory
    cp $SUBMISSION_FILES /autograder/source
    cd /autograder/source
fi

# make sure compiles without error
echo -n "Compiler Error" > $NAME
for f in $SUBMISSION_FILES; do
    [[ "$f" == *.py ]] && python -m py_compile "$f" 2>> $OUTPUT
    sed -i 's/^Sorry: //' $OUTPUT
done
if [[ -s $OUTPUT ]]; then abort; fi

# check for any forbidden code
echo -n "Security Audit" > $NAME
python -m jmu_pytest_utils.audit $SUBMISSION_FILES >> $OUTPUT
if [[ -s $OUTPUT ]]; then abort; fi

# create initial results.json file
python -m jmu_pytest_utils.limit
if [ $? -ne 0 ]; then
  if [ -d /autograder/results ]; then
    cp results.json /autograder/results
  fi
  exit  # submission limit exceeded
fi

# run pytest and emit the results
pytest --timeout=$FUNCTION_TIMEOUT $AUTOGRADER_TESTS >> $OUTPUT
if [ -d /autograder/results ]; then
    cp results.json /autograder/results
fi
